{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1hIW974jaSZ3WBlUFb+gm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manjunathgoli/Deep_Research_AI_Agent/blob/main/Deep_Research_AI_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community\n",
        "!pip install langgraph\n",
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "import os\n",
        "import torch\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.tools import TavilySearchResults\n",
        "from langgraph.graph import StateGraph\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPTODUV-DGe1",
        "outputId": "39d74b49-50c9-4e9d-da51-95f28a175272"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.19)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.41)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.20 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.20)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.38)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.13)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.8.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.11)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain-community) (0.3.6)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.20->langchain-community) (2.10.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.41->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.20->langchain-community) (2.27.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.3.5)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.41)\n",
            "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.0.17)\n",
            "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.2)\n",
            "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.55)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (0.3.11)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (2.10.6)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.1.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Tavily API key\n",
        "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
        "if not TAVILY_API_KEY:\n",
        "    raise ValueError(\"TAVILY_API_KEY is missing. Set it in environment variables.\")"
      ],
      "metadata": {
        "id": "rBkSeDVEDGbX"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up device and model\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_name = \"facebook/bart-large-cnn\"\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "Sz2lKFcbDGY8"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Research Agent\n",
        "class ResearchAgent:\n",
        "    def __call__(self, state):\n",
        "        search_tool = TavilySearchResults(tavily_api_key=TAVILY_API_KEY)\n",
        "        query = state[\"question\"]\n",
        "        results = search_tool.run(query)\n",
        "\n",
        "        if not results:\n",
        "            state[\"research_data\"] = []\n",
        "            state[\"source_urls\"] = []\n",
        "            return state\n",
        "\n",
        "        urls = [result[\"url\"] for result in results if isinstance(result, dict) and \"url\" in result]\n",
        "        state[\"research_data\"] = results\n",
        "        state[\"source_urls\"] = urls\n",
        "        return state"
      ],
      "metadata": {
        "id": "UdRW_JCbDGWw"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Term Expansion Agent\n",
        "class TermExpansionAgent:\n",
        "    def __call__(self, state):\n",
        "        unknown_terms = extract_unknown_terms(state[\"research_data\"], state[\"question\"])\n",
        "        if unknown_terms:\n",
        "            search_tool = TavilySearchResults(tavily_api_key=TAVILY_API_KEY)\n",
        "            definitions = {term: search_tool.run(term) for term in unknown_terms}\n",
        "            state[\"definitions\"] = definitions\n",
        "        return state"
      ],
      "metadata": {
        "id": "vn-7X4UMDGUK"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarization Agent\n",
        "class SummarizationAgent:\n",
        "    def __call__(self, state):\n",
        "        context = state.get(\"research_data\", [])\n",
        "        if \"definitions\" in state:\n",
        "            context += str(state[\"definitions\"])\n",
        "\n",
        "        if isinstance(context, list):\n",
        "            context = \" \".join(str(item) for item in context)\n",
        "\n",
        "        if not context.strip():\n",
        "            state[\"summary\"] = \"No relevant research data available.\"\n",
        "            return state\n",
        "\n",
        "        input_text = \"summarize: \" + context\n",
        "        inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True).to(device)\n",
        "\n",
        "        if inputs.input_ids.shape[1] == 0:\n",
        "            state[\"summary\"] = \"Failed to generate a summary due to empty input.\"\n",
        "            return state\n",
        "\n",
        "        summary_ids = model.generate(**inputs, max_length=512, min_length=150, length_penalty=2.0)\n",
        "        state[\"summary\"] = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "        return state"
      ],
      "metadata": {
        "id": "mG1SuaiyDGR9"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Answer Agent\n",
        "class AnswerAgent:\n",
        "    def __call__(self, state):\n",
        "        context = state.get(\"research_data\", [])\n",
        "        if \"definitions\" in state:\n",
        "            context += str(state[\"definitions\"])\n",
        "\n",
        "        if isinstance(context, list):\n",
        "            context = \" \".join(str(item) for item in context)\n",
        "\n",
        "        if not context.strip():\n",
        "            state[\"answer_text\"] = \"No content available for answering.\"\n",
        "            return state\n",
        "\n",
        "        input_text = \"summarize: \" + context\n",
        "        inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=1024, truncation=True).to(device)\n",
        "\n",
        "        if inputs.input_ids.shape[1] == 0:\n",
        "            state[\"answer_text\"] = \"Failed to generate an answer due to empty input.\"\n",
        "            return state\n",
        "\n",
        "        summary_ids = model.generate(**inputs, max_length=512, min_length=50)\n",
        "        state[\"answer_text\"] = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "        sources = state.get(\"source_urls\", [])\n",
        "        if sources:\n",
        "            state[\"answer_text\"] += \"\\n\\nSources:\\n\" + \"\\n\".join(sources)\n",
        "\n",
        "        return state"
      ],
      "metadata": {
        "id": "Lfj1S884DGPp"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_unknown_terms(research_data, query):\n",
        "    return []"
      ],
      "metadata": {
        "id": "aQX0wyATDGNd"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the state structure\n",
        "from typing import TypedDict, List\n",
        "\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    research_data: List[str]\n",
        "    definitions: dict\n",
        "    summary: str\n",
        "    answer_text: str\n",
        "    source_urls: List[str]\n",
        "\n",
        "# Construct the graph\n",
        "graph = StateGraph(State)\n",
        "graph.add_node(\"research\", ResearchAgent())\n",
        "graph.add_node(\"term_expansion\", TermExpansionAgent())\n",
        "graph.add_node(\"summarization\", SummarizationAgent())\n",
        "graph.add_node(\"answer\", AnswerAgent())\n",
        "\n",
        "# Define transitions\n",
        "graph.add_conditional_edges(\n",
        "    \"research\",\n",
        "    lambda state: \"term_expansion\" if extract_unknown_terms(state[\"research_data\"], state[\"question\"]) else \"summarization\",\n",
        ")\n",
        "graph.add_edge(\"term_expansion\", \"summarization\")\n",
        "graph.add_edge(\"summarization\", \"answer\")\n",
        "\n",
        "graph.set_entry_point(\"research\")\n",
        "compiled_graph = graph.compile()"
      ],
      "metadata": {
        "id": "ZR8uHRvnDGK1"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to run the system\n",
        "def runsystem(query):\n",
        "    state = {\n",
        "        \"question\": query,\n",
        "        \"research_data\": [],\n",
        "        \"definitions\": {},\n",
        "        \"summary\": \"\",\n",
        "        \"answer_text\": \"\",\n",
        "        \"source_urls\": [],\n",
        "    }\n",
        "    final_state = compiled_graph.invoke(state)\n",
        "\n",
        "    if not final_state.get(\"research_data\"):\n",
        "        print(\"No research data available for summarization.\")\n",
        "    else:\n",
        "        print(\"\\nGenerated Answer:\\n\")\n",
        "        print(final_state.get(\"answer_text\", \"No answer generated.\"))\n",
        "\n",
        "        sources = final_state.get(\"source_urls\", [])\n",
        ""
      ],
      "metadata": {
        "id": "qKkqKrRnDGIf"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    query = input(\"Enter your research question: \")\n",
        "    runsystem(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lzm_zOpDDGF8",
        "outputId": "a680c8ea-481e-4721-8c60-f32ec0697245"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your research question:  describe about lions\n",
            "\n",
            "Generated Answer:\n",
            "\n",
            "The lion (Panthera leo) is a large cat of the genus Panthera, native to Africa and India. Nearly all wild lions live in Africa, but one small population exists elsewhere. Male lions can weigh 30 stone. Up to 80 percent of lion cubs die within their first 2 years of life.\n",
            "\n",
            "Sources:\n",
            "https://en.wikipedia.org/wiki/Lion\n",
            "https://www.wwf.org.uk/learn/fascinating-facts/lions\n",
            "https://www.britannica.com/animal/lion\n",
            "https://nationalzoo.si.edu/animals/lion\n"
          ]
        }
      ]
    }
  ]
}